Reflectieverslag Samenwerking – Pygame Development Project

1. Samenwerkingspartner

Naam: ChatGPT (OpenAI‑taalmodel)
Rol: Virtuele programmeercoach & code‑reviewerSamenwerkingsvorm: Asynchrone tekstchat in ChatGPT‑sessies (zie chatlogs in Appendix A).

2. Projectoverzicht

Voor het Introductieproject moest ik een Blackjack‑spel bouwen in Python met Pygame. Ik koos ervoor om ChatGPT als sparringpartner te gebruiken. ChatGPT hielp mij bij:

verduidelijken van onduidelijke concepten uit de YouTube‑tutorial;

code‑reviews (bijv. uitleg over hand_active vs. reveal_dealer);

foutopsporing wanneer variabelen niet bestonden (game_deck‑vraag);

herschrijven van code met uitgebreide inline‑commentaar.
We communiceerden meerdere keren per week tussen 1 april 2025 en 30 mei 2025, telkens 10‑30 minuten per sessie.

3. Communicatie

Kanaal: ChatGPT‑interface (web).

Stijl: Korte, gerichte vragen; ChatGPT antwoordde met voorbeeldcode, tabellen en uitleg in het Nederlands of Engels.

Tools: Kopiëren‑&‑plakken van codefragmenten tussen VS Code en de chat.

Uitdagingen:

Soms te algemene antwoorden → ik leerde preciezer formuleren (context + foutmelding).

Antwoorden bevatten af‑en‑toe kleine codefouten; ik moest testen en terugrapporteren.

Succesfactoren: Snel itereren, meteen nieuwe vragen stellen binnen dezelfde sessie.

4. Rollen & verantwoordelijkheden

Taak

Mijn rol

Rol ChatGPT

Game‑logica implementeren

Schrijven & testen code

N.v.t.

Conceptuele uitleg (Pygame, Blackjack‑regels)

Leervragen formuleren

Didactische uitleg geven

Code‑review & best‑practices

Code delen ter feedback

Voorstellen van verbeterpunten

Debuggen

Uitvoeren van tests, error‑logs verzamelen

Hypotheses en oplossingen aandragen

De rollen sloten goed aan bij onze competenties: ik programmeerde; ChatGPT leverde domeinkennis en feedback.

5. Teamwork & bijdrage

De bijdrage was complementair, niet gelijk. ChatGPT leverde kennis en alternatieve oplossingen; ik voerde alle wijzigingen uit, testte en besloot welke adviezen te implementeren. Zonder mijn input (code + vragen) kon ChatGPT niets, maar zonder ChatGPT had ik aanzienlijk meer tijd nodig gehad voor documentatie‑search en foutanalyse.

6. Geleerde lessen (individueel)

Specifieke prompts ⇒ betere antwoorden. Door exact regels of foutmeldingen te tonen kreeg ik direct toepasbare feedback.

Iteratief werken loont. Kleine code‑snippets bespreken voorkomt grote refactors achteraf.

Verifieer elk advies. AI‑antwoorden zijn snel maar niet onfeilbaar; eigen tests blijven cruciaal.

Documenteer tussendoor. Chat‑antwoorden opslaan in README hielp bij het mondeling verdedigen van keuzes.

Modelkeuze maakt verschil. Ik testte zowel GPT‑4o als OpenAI o3.

GPT‑4o gaf vaak uitgebreide maar minder gestructureerde antwoorden en stelde meer verduidelijkingsvragen.

o3 leverde kernachtige tabellen, scenario‑analyses en was beter in het "mee‑denken" met mijn intentie (zie chat op 5 april over hand_active/reveal_dealer).Conclusie: Voor programmeervragen met veel logische branches kies ik voortaan bewust voor o3.

7. Professionele communicatie – vooruitblik

Context + doel vermelden bij elke vraag (zoals in een professioneel support‑ticket).

Versiebeheer gebruiken (Git‑branches) zodat review‑opmerkingen traceerbaar blijven.

Samenvatten & bevestigen aan het einde van een gesprek om misinterpretaties te voorkomen.

Evidence bewaren (chatlogs, screenshots) als bewijs van samenwerking – nuttig voor audits en evaluaties.

8. Conclusie

De samenwerking met ChatGPT was effectief: mijn programmeersnelheid steeg, en ik ontwikkelde scherpere vraagtechnieken. De keuze voor het o3‑model bleek cruciaal voor heldere, goed gestructureerde feedback, terwijl 4o vooral nuttig was voor bredere context. Hoewel een AI‑partner geen menselijke creativiteit of emotie biedt, vulde het perfect de rol van 24/7‑beschikbare mentor. Voor toekomstige projecten blijf ik ChatGPT inzetten, maar combineer ik het met peer‑reviews voor robuustheid.

Appendix A – Bewijs van samenwerking

Chatfragment 1 (5 april 2025): vraag over hand_active vs. reveal_dealer.

Chatfragment 2 (12 april 2025): inline‑commentaar bij volledige broncode.

Chatfragment 3 (28 mei 2025): discussie over check_endgame en add_score‑flag.

Chatfragment 4 (15 mei 2025): vergelijking GPT‑4o vs. o3 bij debug‑vraag.

(Alle fragmenten zijn opgeslagen in het project‑repository onder /evidence/chatlogs/.)

